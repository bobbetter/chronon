package build.cloud_gcp
import mill.api._
import mill.scalalib.*

import java.util.jar.JarFile

// Cloud GCP module - supports both cloud_gcp.test AND cloud_gcp[2.13.17].test
object `package` extends Cross[CloudGcpModule](build.Constants.scalaVersions) with CloudGcpModule {
  // Provide default scala version for bracket-free access
  override val crossValue = build.Constants.defaultScalaVersion
}

trait CloudGcpModule extends Cross.Module[String] with build.BaseModule {
  def moduleDeps = Seq(build.spark(crossValue), build.aggregator(crossValue), build.api(crossValue), build.online(crossValue))
  def bigqueryJarFile = Task.Source(moduleDir / "iceberg-bigquery-1.11.0-SNAPSHOT.jar")

  // Versions force-overridden to fix CVEs from uber-jar transitive deps.
  // Also used by patchAssemblyMetadata to write correct pom.properties.
  private val avroVersion = build.Constants.avroVersion

  def excludeJackson(dep: mill.scalalib.Dep): mill.scalalib.Dep = {
    dep
      .exclude("com.fasterxml.jackson.core" -> "jackson-core")
      .exclude("com.fasterxml.jackson.core" -> "jackson-databind")
      .exclude("com.fasterxml.jackson.core" -> "jackson-annotations")
      .exclude("com.fasterxml.jackson.datatype" -> "jackson-datatype-jsr310")
  }

  // Merge strategy for assembly
  // Needed to avoid conflicts with Dataproc serverless
//  override def assemblyRules = super.assemblyRules ++ Seq(
//    Assembly.Rule.Relocate("org.apache.iceberg.gcp.bigquery.**", "shade.org.apache.iceberg.gcp.bigquery.@1")
//  )
  override def assemblyRules = super.assemblyRules ++ Seq(
    // Uber-jars (iceberg-spark-runtime) embed stale pom.properties that override
    // the correct versions during assembly merge. Exclude conflicting metadata here;
    // the assembly task patches the correct versions back in from our resolved dependencies.
    Assembly.Rule.ExcludePattern("META-INF/maven/org\\.apache\\.avro/.*"),
  )

  override def unmanagedClasspath = Task {
    super.unmanagedClasspath() ++ Seq(bigqueryJarFile())
  }

  // Uber-jars (iceberg-spark-runtime) embed stale pom.properties that win the assembly
  // merge. assemblyRules strips all copies; this method patches the correct versions
  // back so grype/SBOM tools see the actual versions on the classpath.
  private val patchedMetadata: Seq[(String, String, String)] = Seq(
    ("org.apache.avro", "avro", avroVersion),
  )

  private def patchAssemblyMetadata(jar: os.Path): Unit = {
    val uri = java.net.URI.create("jar:" + jar.toIO.toURI)
    val env = new java.util.HashMap[String, String]()
    val fs = java.nio.file.FileSystems.newFileSystem(uri, env)
    try {
      patchedMetadata.foreach { case (groupId, artifactId, version) =>
        val entry = fs.getPath(s"META-INF/maven/$groupId/$artifactId/pom.properties")
        java.nio.file.Files.createDirectories(entry.getParent)
        val content = s"artifactId=$artifactId\ngroupId=$groupId\nversion=$version\n"
        java.nio.file.Files.write(entry, content.getBytes(java.nio.charset.StandardCharsets.UTF_8))
      }
    } finally {
      fs.close()
    }
  }

  override def assembly = Task {
    val result = super.assembly()
    val out = Task.dest / "out.jar"
    os.copy(result.path, out)
    patchAssemblyMetadata(out)
    PathRef(out)
  }

  def compileMvnDeps = build.Constants.sparkDeps ++ Seq(
    mvn"com.google.cloud.spark:spark-3.5-bigquery:0.42.0",
  )

//  val googleBigdataVersion = "2.2.26"
  def mvnDeps = build.Constants.commonDeps ++
    build.Constants.loggingApiDeps ++
    build.Constants.utilityDeps ++
    Seq(
      mvn"com.google.cloud:google-cloud-storage:2.49.0",
      mvn"com.google.cloud:google-cloud-dataproc:4.52.0",
      mvn"com.google.cloud:google-cloud-pubsub:1.134.2",
      mvn"com.google.cloud.hosted.kafka:managed-kafka-auth-login-handler:1.0.6",
      mvn"org.apache.iceberg::iceberg-spark-runtime-3.5:1.10.0",
      mvn"com.google.cloud:google-cloud-bigquery:2.54.1",
      mvn"com.google.cloud:google-cloud-bigtable:2.57.1",
      mvn"com.google.cloud:google-cloud-aiplatform:3.79.0",
      mvn"io.vertx:vertx-web-client:4.5.24",
      mvn"com.google.auth:google-auth-library-oauth2-http:1.40.0",
  ).map(excludeJackson) ++ Seq(
    mvn"com.fasterxml.jackson.core:jackson-core:${build.Constants.jacksonVersion}",
    mvn"com.fasterxml.jackson.core:jackson-databind:${build.Constants.jacksonVersion}",
    mvn"com.fasterxml.jackson.core:jackson-annotations:${build.Constants.jacksonVersion}",
    mvn"com.fasterxml.jackson.module::jackson-module-scala:${build.Constants.jacksonVersion}",
    mvn"com.fasterxml.jackson.datatype:jackson-datatype-jsr310:${build.Constants.jacksonVersion}",
    mvn"org.apache.avro:avro:$avroVersion"
      .exclude("com.fasterxml.jackson.core" -> "jackson-core")
      .exclude("com.fasterxml.jackson.core" -> "jackson-databind")
      .exclude("com.fasterxml.jackson.core" -> "jackson-annotations"),
  ).map(_.forceVersion())
  
  object test extends build.BaseTestModule {
    def scalaVersion = crossValue

    def moduleDeps = Seq(build.cloud_gcp(crossValue), build.spark(crossValue).test)
    override def testFramework = "org.scalatest.tools.Framework"
    def forkArgs = build.Constants.commonTestForkArgs ++ Seq(
      "-Dspark.sql.adaptive.enabled=false",
      "-Dspark.sql.adaptive.coalescePartitions.enabled=false",
      "-Dspark.serializer=org.apache.spark.serializer.KryoSerializer",
      "-Dspark.sql.hive.convertMetastoreParquet=false"
    )

    def compileMvnDeps = build.Constants.sparkDeps ++ Seq(
      mvn"org.apache.iceberg:iceberg-bigquery:1.10.0",
    )

    override def mvnDeps = super.mvnDeps() ++ build.Constants.sparkDeps ++ build.Constants.testDeps ++ Seq(
      excludeJackson(mvn"com.google.cloud.spark:spark-3.5-bigquery:0.42.0"),
      // Use exact versions from Bazel configuration
      excludeJackson(mvn"com.google.cloud:google-cloud-bigtable-emulator:0.178.0")
        .exclude("io.grpc" -> "grpc-core")
        .exclude("io.grpc" -> "grpc-stub")
        .exclude("io.grpc" -> "grpc-inprocess")
        .exclude("com.google.api" -> "gax")
        .exclude("com.google.api" -> "gax-grpc"),
    )
  }
}