name: Publish Release
on:
  release:
    types: [published]

env:
  VERSION: ${{ github.event.release.tag_name }}

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}

jobs:
  check_if_latest:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: read
    steps:
      - name: Checkout platform repo
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Check if Release is Latest
        id: check_latest
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          CURRENT_TAG=${{ env.VERSION }}
          LATEST_TAG=$(gh release view --json tagName --jq '.tagName')

          if [ "$CURRENT_TAG" = "$LATEST_TAG" ]; then
            echo "IS_LATEST=true" >> $GITHUB_OUTPUT
          else
            echo "IS_LATEST=false" >> $GITHUB_OUTPUT
          fi

    outputs:
      is_latest: ${{ steps.check_latest.outputs.IS_LATEST }}

  # We need to rebuild the wheel to bake in the new version number
  build_python_wheel:
    runs-on: ubuntu-latest
    needs: [check_if_latest]

    steps:
      - name: Checkout chronon repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11' # This should match the version used in [chronon]/.toolversions

      - name: Install Thrift
        env:
          THRIFT_VERSION: 0.21.0
        run: |
          sudo apt-get update -y && \
          sudo apt-get install -y automake bison flex g++ git libboost-all-dev libevent-dev libssl-dev libtool make pkg-config && \
          curl -LSs https://archive.apache.org/dist/thrift/${{env.THRIFT_VERSION}}/thrift-${{env.THRIFT_VERSION}}.tar.gz -o thrift-${{env.THRIFT_VERSION}}.tar.gz && \
          tar -xzf thrift-${{env.THRIFT_VERSION}}.tar.gz && \
          cd thrift-${{env.THRIFT_VERSION}} && \
          sudo ./configure --without-python --without-cpp --without-nodejs --without-java --disable-debug --disable-tests --disable-libs && \
          sudo make && \
          sudo make install && \
          cd .. && \
          sudo rm -rf thrift-${{env.THRIFT_VERSION}} thrift-${{env.THRIFT_VERSION}}.tar.gz

      - name: Run Python Build Script
        id: build-wheel
        run: |
          CHRONON_VERSION=${VERSION#v}  ./mill python.wheel
          EXPECTED_WHEEL_DIR=./out/python/wheel.dest/dist
          EXPECTED_ZIPLINE_WHEEL="zipline_ai-${VERSION#v}-py3-none-any.whl"
          if [ ! -f "$EXPECTED_WHEEL_DIR/$EXPECTED_ZIPLINE_WHEEL" ]; then
            echo "$EXPECTED_ZIPLINE_WHEEL not found"
            exit 1
          fi
          cp $EXPECTED_WHEEL_DIR/$EXPECTED_ZIPLINE_WHEEL .
          echo "wheel_file=$EXPECTED_ZIPLINE_WHEEL" >> $GITHUB_OUTPUT

      - name: Upload Wheel Artifact
        uses: actions/upload-artifact@v4
        with:
          name: zipline-ai-wheel
          path: ${{ steps.build-wheel.outputs.wheel_file }}

    outputs:
      wheel_file: ${{ steps.build-wheel.outputs.wheel_file }}

  download_passing_candidate_jars:
    runs-on: ubuntu-latest
    environment: main
    needs: [check_if_latest]
    permissions:
      contents: read
      id-token: write

    steps:
      - name: Configure GCP Credentials
        uses: google-github-actions/auth@v2
        with:
          project_id: ${{secrets.GCP_MAIN_PROJECT_ID}}
          workload_identity_provider: projects/${{secrets.GCP_MAIN_PROJECT_NUMBER}}/locations/global/workloadIdentityPools/github-actions/providers/github
          service_account: github-actions@${{secrets.GCP_MAIN_PROJECT_ID}}.iam.gserviceaccount.com

      - name: Set up Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{secrets.AWS_ACCOUNT_ID}}:role/github_actions
          aws-region: ${{secrets.AWS_REGION}}

      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Download GCP JARs
        run: |
          mkdir -p gcp-jars
          gcloud storage cp gs://zipline-artifacts-canary/release/passing-candidate/jars/* gcp-jars/

      - name: Download AWS JARs
        run: |
          mkdir -p aws-jars
          aws s3 cp s3://zipline-artifacts-canary/release/passing-candidate/jars/ aws-jars/ --recursive

      - name: Download Azure JARs
        run: |
          mkdir -p azure-jars
          az storage blob download-batch \
            --account-name ziplineai2 \
            --auth-mode login \
            --source dev-zipline-artifacts \
            --pattern "release/passing-candidate/jars/*" \
            --destination azure-jars/ \
            --no-progress
          mv azure-jars/release/passing-candidate/jars/* azure-jars/
          rm -rf azure-jars/release

      - name: Upload GCP JARs artifact
        uses: actions/upload-artifact@v4
        with:
          name: passing-candidate-gcp-jars
          path: gcp-jars/

      - name: Upload AWS JARs artifact
        uses: actions/upload-artifact@v4
        with:
          name: passing-candidate-aws-jars
          path: aws-jars/

      - name: Upload Azure JARs artifact
        uses: actions/upload-artifact@v4
        with:
          name: passing-candidate-azure-jars
          path: azure-jars/

  publish_to_pypi:
    runs-on: ubuntu-latest
    needs: [build_python_wheel]
    environment: pypi
    permissions:
      id-token: write  # Required for trusted publishing (OIDC)

    steps:
      - name: Download Python Wheel Artifact
        uses: actions/download-artifact@v4
        with:
          name: zipline-ai-wheel
          path: dist/

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          packages-dir: dist/

  promote-gcp-candidate:
    runs-on: ubuntu-latest
    needs: [check_if_latest, build_python_wheel, download_passing_candidate_jars]

    permissions:
      id-token: write
      contents: write

    steps:
      - name: Checkout platform repo
        uses: actions/checkout@v4

      - name: Configure GCP Credentials for Main Project
        uses: google-github-actions/auth@v2
        with:
          project_id: ${{secrets.GCP_MAIN_PROJECT_ID}}
          workload_identity_provider: projects/${{secrets.GCP_MAIN_PROJECT_NUMBER}}/locations/global/workloadIdentityPools/github-actions/providers/github
          service_account: github-actions@${{secrets.GCP_MAIN_PROJECT_ID}}.iam.gserviceaccount.com

      - name: Set up Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Download Python Wheel Artifact
        uses: actions/download-artifact@v4
        with:
          name: zipline-ai-wheel

      - name: Download GCP JARs
        uses: actions/download-artifact@v4
        with:
          name: passing-candidate-gcp-jars
          path: jars/

      - name: Upload GCP Artifacts to Customer Buckets
        shell: bash
        run: |
          set -eo pipefail

          for customer_id in "canary" "etsy" "base" "dev"; do
            echo "Uploading wheel to GCS for customer_id: $customer_id"
            gcloud storage cp ${{ needs.build_python_wheel.outputs.wheel_file }} gs://zipline-artifacts-${customer_id}/release/${VERSION#v}/wheels/${{ needs.build_python_wheel.outputs.wheel_file }}
            gcloud storage objects update gs://zipline-artifacts-${customer_id}/release/${VERSION#v}/wheels/${{ needs.build_python_wheel.outputs.wheel_file }} --custom-metadata="updated_date=$(date),commit=$(git rev-parse HEAD),branch=$(git rev-parse --abbrev-ref HEAD)"
            if [ "${{ needs.check_if_latest.outputs.is_latest }}" == "true" ]; then
              gcloud storage rm gs://zipline-artifacts-${customer_id}/release/latest/wheels/* || true
              gcloud storage cp ${{ needs.build_python_wheel.outputs.wheel_file }} gs://zipline-artifacts-${customer_id}/release/latest/wheels/${{ needs.build_python_wheel.outputs.wheel_file }}
              gcloud storage objects update gs://zipline-artifacts-${customer_id}/release/latest/wheels/${{ needs.build_python_wheel.outputs.wheel_file }} --custom-metadata="updated_date=$(date),commit=$(git rev-parse HEAD),branch=$(git rev-parse --abbrev-ref HEAD)"
            fi
            echo "Uploading jars to GCS for customer_id: $customer_id"
            for jar in jars/*.jar; do
              jar_name=$(basename $jar)
              gcloud storage cp $jar gs://zipline-artifacts-${customer_id}/release/${VERSION#v}/jars/$jar_name
              gcloud storage objects update gs://zipline-artifacts-${customer_id}/release/${VERSION#v}/jars/$jar_name --custom-metadata="updated_date=$(date),commit=$(git rev-parse HEAD),branch=$(git rev-parse --abbrev-ref HEAD)"
              if [ "${{ needs.check_if_latest.outputs.is_latest }}" == "true" ]; then
                gcloud storage cp $jar gs://zipline-artifacts-${customer_id}/release/latest/jars/$jar_name
                gcloud storage objects update gs://zipline-artifacts-${customer_id}/release/latest/jars/$jar_name --custom-metadata="updated_date=$(date),commit=$(git rev-parse HEAD),branch=$(git rev-parse --abbrev-ref HEAD)"
              fi
            done
          done
          echo "Artifacts uploaded to GCS"

      - name: Attach Wheel to Release
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

        run: |
          gh release upload $VERSION ${{ needs.build_python_wheel.outputs.wheel_file }}

      - name: Attach JARs to Release
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          for jar in jars/*.jar; do
            gh release upload $VERSION $jar
          done

      # Setup JFrog CLI
      - name: Setup JFrog CLI
        uses: jfrog/setup-jfrog-cli@v4

      - name: Configure JFrog CLI with Access Token
        run: |
          jf config add artifactory \
            --url="${{ secrets.ARTIFACTORY_URL }}" \
            --access-token="${{ secrets.ARTIFACTORY_TOKEN }}" \
            --interactive=false

      - name: Upload Wheel to Artifactory
        run: |
          jf rt upload ${{ needs.build_python_wheel.outputs.wheel_file }} "wheels/${VERSION#v}/"

      - name: Upload JARs to Artifactory
        run: |
          for jar in jars/*.jar; do
            jf rt upload $jar "jars/${VERSION#v}/"
          done

  promote-aws-candidate:
    runs-on: ubuntu-latest
    needs: [check_if_latest, build_python_wheel, download_passing_candidate_jars]

    permissions:
      id-token: write
      contents: write

    steps:
      - name: Checkout platform repo
        uses: actions/checkout@v4

      - name: Configure AWS Credentials for Main Project
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{secrets.AWS_ACCOUNT_ID}}:role/github_actions
          aws-region: ${{secrets.AWS_REGION}}

      - name: Download Python Wheel Artifact
        uses: actions/download-artifact@v4
        with:
          name: zipline-ai-wheel

      - name: Download AWS JARs
        uses: actions/download-artifact@v4
        with:
          name: passing-candidate-aws-jars
          path: jars/

      - name: Upload AWS Artifacts to Customer Buckets
        shell: bash
        run: |
          set -eo pipefail

          for customer_id in "canary" "base" "dev" "plaid"; do
            echo "Uploading wheel to S3 for customer_id: $customer_id"
            aws s3 cp ${{ needs.build_python_wheel.outputs.wheel_file }} s3://zipline-artifacts-${customer_id}/release/${VERSION#v}/wheels/${{ needs.build_python_wheel.outputs.wheel_file }} --metadata="updated_date=$(date),commit=$(git rev-parse HEAD),branch=$(git rev-parse --abbrev-ref HEAD)"
            if [ "${{ needs.check_if_latest.outputs.is_latest }}" == "true" ]; then
              aws s3 rm s3://zipline-artifacts-${customer_id}/release/latest/wheels/ --recursive || true
              aws s3 cp ${{ needs.build_python_wheel.outputs.wheel_file }} s3://zipline-artifacts-${customer_id}/release/latest/wheels/${{ needs.build_python_wheel.outputs.wheel_file }} --metadata="updated_date=$(date),commit=$(git rev-parse HEAD),branch=$(git rev-parse --abbrev-ref HEAD)"
            fi
            echo "Uploading jars to S3 for customer_id: $customer_id"
            for jar in jars/*.jar; do
              jar_name=$(basename $jar)
              aws s3 cp $jar s3://zipline-artifacts-${customer_id}/release/${VERSION#v}/jars/$jar_name --metadata="updated_date=$(date),commit=$(git rev-parse HEAD),branch=$(git rev-parse --abbrev-ref HEAD)"
              if [ "${{ needs.check_if_latest.outputs.is_latest }}" == "true" ]; then
                aws s3 cp $jar s3://zipline-artifacts-${customer_id}/release/latest/jars/$jar_name --metadata="updated_date=$(date),commit=$(git rev-parse HEAD),branch=$(git rev-parse --abbrev-ref HEAD)"
              fi
            done
          done

      - name: Attach JARs to Release
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          for jar in jars/*.jar; do
            gh release upload $VERSION $jar
          done

      # Setup JFrog CLI
      - name: Setup JFrog CLI
        uses: jfrog/setup-jfrog-cli@v4
        with:
          version: latest

      - name: Configure JFrog CLI with Access Token
        run: |
          jf config add artifactory \
            --url="${{ secrets.ARTIFACTORY_URL }}" \
            --access-token="${{ secrets.ARTIFACTORY_TOKEN }}" \
            --interactive=false

      - name: Upload JARs to Artifactory
        run: |
          for jar in jars/*.jar; do
            jf rt upload $jar "jars/${VERSION#v}/"
          done

  promote-azure-candidate:
    runs-on: ubuntu-latest
    needs: [check_if_latest, build_python_wheel, download_passing_candidate_jars]
    environment: main

    permissions:
      id-token: write
      contents: write

    steps:
      - name: Checkout platform repo
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Download Python Wheel Artifact
        uses: actions/download-artifact@v4
        with:
          name: zipline-ai-wheel

      - name: Download Azure JARs
        uses: actions/download-artifact@v4
        with:
          name: passing-candidate-azure-jars
          path: jars/

      - name: Upload Azure Artifacts to Customer Buckets
        shell: bash
        run: |
          set -eo pipefail
          ACCOUNT="ziplineai2"
          CONTAINER="dev-zipline-artifacts"

          for customer_id in "canary" "base" "dev"; do
            echo "Uploading wheel to Azure for customer_id: $customer_id"
            az storage blob upload \
              --account-name $ACCOUNT \
              --auth-mode login \
              --container-name $CONTAINER \
              --file ${{ needs.build_python_wheel.outputs.wheel_file }} \
              --name release/${VERSION#v}/wheels/${{ needs.build_python_wheel.outputs.wheel_file }} \
              --tier cool \
              --overwrite

            if [ "${{ needs.check_if_latest.outputs.is_latest }}" == "true" ]; then
              az storage blob upload \
                --account-name $ACCOUNT \
                --auth-mode login \
                --container-name $CONTAINER \
                --file ${{ needs.build_python_wheel.outputs.wheel_file }} \
                --name release/latest/wheels/${{ needs.build_python_wheel.outputs.wheel_file }} \
                --tier cool \
                --overwrite
            fi

            echo "Uploading jars to Azure for customer_id: $customer_id"
            for jar in jars/*.jar; do
              jar_name=$(basename $jar)
              az storage blob upload \
                --account-name $ACCOUNT \
                --auth-mode login \
                --container-name $CONTAINER \
                --file $jar \
                --name release/${VERSION#v}/jars/$jar_name \
                --tier cool \
                --overwrite

              if [ "${{ needs.check_if_latest.outputs.is_latest }}" == "true" ]; then
                az storage blob upload \
                  --account-name $ACCOUNT \
                  --auth-mode login \
                  --container-name $CONTAINER \
                  --file $jar \
                  --name release/latest/jars/$jar_name \
                  --tier cool \
                  --overwrite
              fi
            done
          done
          echo "Artifacts uploaded to Azure Blob Storage"

      - name: Attach JARs to Release
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          for jar in jars/*.jar; do
            gh release upload $VERSION $jar
          done

      # Setup JFrog CLI
      - name: Setup JFrog CLI
        uses: jfrog/setup-jfrog-cli@v4
        with:
          version: latest

      - name: Configure JFrog CLI with Access Token
        run: |
          jf config add artifactory \
            --url="${{ secrets.ARTIFACTORY_URL }}" \
            --access-token="${{ secrets.ARTIFACTORY_TOKEN }}" \
            --interactive=false

      - name: Upload JARs to Artifactory
        run: |
          for jar in jars/*.jar; do
            jf rt upload $jar "jars/${VERSION#v}/"
          done

  build_engine_images:
    runs-on: ubuntu-latest
    needs: [check_if_latest, download_passing_candidate_jars]
    strategy:
      fail-fast: true
      matrix:
        cloud: [gcp, aws, azure]
    permissions:
      contents: read

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Download JARs
        uses: actions/download-artifact@v4
        with:
          name: passing-candidate-${{ matrix.cloud }}-jars
          path: build_output/engine/

      - name: Create engine manifest
        run: |
          echo '{"version": "${{ env.VERSION }}", "cloud": "${{ matrix.cloud }}", "commit": "${{ github.sha }}"}' > build_output/engine_manifest.json

      - name: Build and push engine image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: docker/engine/Dockerfile
          build-args: |
            VERSION=${{ env.VERSION }}
          platforms: linux/amd64
          push: true
          tags: |
            ziplineai/engine-${{ matrix.cloud }}:${{ github.sha }}
            ${{ env.VERSION && format('ziplineai/engine-{0}:{1}', matrix.cloud, env.VERSION) || '' }}
            ${{ needs.check_if_latest.outputs.is_latest == 'true' && format('ziplineai/engine-{0}:latest', matrix.cloud) || '' }}

  build_and_publish_docker:
    runs-on: ubuntu-latest
    environment: main
    needs: [check_if_latest, download_passing_candidate_jars]
    permissions:
      contents: read
      packages: read
      attestations: write
      id-token: write

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Download GCP JARs
        uses: actions/download-artifact@v4
        with:
          name: passing-candidate-gcp-jars
          path: gcp-jars/

      - name: Download AWS JARs
        uses: actions/download-artifact@v4
        with:
          name: passing-candidate-aws-jars
          path: aws-jars/

      - name: Download Azure JARs
        uses: actions/download-artifact@v4
        with:
          name: passing-candidate-azure-jars
          path: azure-jars/

      - name: Prepare build artifacts
        run: |
          mkdir -p build_output
          cp gcp-jars/cloud_gcp_lib_deploy.jar build_output/
          cp aws-jars/cloud_aws_lib_deploy.jar build_output/
          cp azure-jars/cloud_azure_lib_deploy.jar build_output/
          cp gcp-jars/service_assembly_deploy.jar build_output/

      - name: Build and push Fetcher Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: docker/fetcher/Dockerfile
          platforms: linux/amd64, linux/arm64
          sbom: true
          provenance: true
          push: true
          tags: |
            ziplineai/chronon-fetcher:${{ github.sha }}
            ${{ env.VERSION && format('ziplineai/chronon-fetcher:{0}', env.VERSION) || '' }}
            ${{ needs.check_if_latest.outputs.is_latest == 'true' && 'ziplineai/chronon-fetcher:latest' || '' }}

      - name: Clean up build artifacts
        run: rm -rf build_output

  on_fail_notify_slack:
    needs: [ publish_to_pypi, promote-aws-candidate, promote-gcp-candidate, promote-azure-candidate, build_and_publish_docker, build_engine_images ]
    if: failure()
    runs-on: ubuntu-latest

    steps:
      - name: Send Failure Notification
        uses: slackapi/slack-github-action@v1
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_TESTS_WEBHOOK_URL }}
        with:
          payload: |
            {
              "text": "Zipline CI Publish Release Failed\n\n Publishing the release failed for version <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|${{ env.VERSION }}>. Please check the logs for more details.",
              "attachments": [
                {
                  "text": "",
                  "color": "#ff0000"
                }
              ]
            }

  clean_up_artifacts:
    permissions:
      id-token: write
      contents: read

    runs-on: ubuntu-latest

    needs: [ promote-aws-candidate, promote-gcp-candidate, promote-azure-candidate, build_and_publish_docker, build_engine_images ]

    steps:
      - name: Delete Artifacts
        uses: geekyeggo/delete-artifact@v5
        with:
          name: |
            zipline-ai-wheel
            passing-candidate-gcp-jars
            passing-candidate-aws-jars
            passing-candidate-azure-jars
