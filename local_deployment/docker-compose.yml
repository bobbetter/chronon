services:
  chronon-spark:
    build:
      context: ..
      dockerfile: local_deployment/chronon-spark/Dockerfile

    environment:
      CHRONON_DRIVER_JAR: /srv/chronon/jars/chronon-spark-assembly.jar
      CHRONON_ONLINE_JAR: /srv/chronon/jars/chronon-aws-assembly.jar
      CHRONON_ONLINE_CLASS: ai.chronon.integrations.aws.AwsApiImpl
      USER: spark
      SPARK_SUBMIT_PATH: /opt/spark/bin/spark-submit
      SPARK_CONF_DIR: /srv/chronon/conf
      JOB_MODE: local[*]
      PARALLELISM: 2
      EXECUTOR_MEMORY: 2G
      EXECUTOR_CORES: 4
      DRIVER_MEMORY: 1G
      DDB_BULKPUT_BATCH_SIZE: 100
      DYNAMO_ENDPOINT: http://dynamodb-local:8000
      AWS_DEFAULT_REGION: us-west-2
      AWS_ACCESS_KEY_ID: local
      AWS_SECRET_ACCESS_KEY: local
      CLOUD_PROVIDER: AWS

    volumes:
      - ../out/spark/assembly.dest/chronon-spark-assembly.jar:/srv/chronon/jars/chronon-spark-assembly.jar:ro
      - ../out/cloud_aws/assembly.dest/chronon-aws-assembly.jar:/srv/chronon/jars/chronon-aws-assembly.jar:ro
      - ./app:/srv/chronon/app
      - ./chronon-spark:/srv/chronon/conf:ro
      - ./metastore:/srv/chronon/metastore
    restart: unless-stopped
    networks:
      - chronon-net

  flink-jobmanager:
    image: flink:1.17.0-scala_2.12-java11  
    container_name: flink-jobmanager
    command: ["jobmanager"]
    environment:
      FLINK_PROPERTIES: "jobmanager.rpc.address: flink-jobmanager"
      DYNAMO_ENDPOINT: http://dynamodb-local:8000
      AWS_DEFAULT_REGION: us-west-2
      AWS_ACCESS_KEY_ID: local
      AWS_SECRET_ACCESS_KEY: local
    ports:
      - "8081:8081"
    networks:
      - chronon-net

  flink-taskmanager:
    image: flink:1.17.0-scala_2.12-java11
    container_name: flink-taskmanager
    command: ["taskmanager"]
    environment:
      FLINK_PROPERTIES: "jobmanager.rpc.address: flink-jobmanager\ntaskmanager.numberOfTaskSlots: 4"
      DYNAMO_ENDPOINT: http://dynamodb-local:8000
      AWS_DEFAULT_REGION: us-west-2
      AWS_ACCESS_KEY_ID: local
      AWS_SECRET_ACCESS_KEY: local
    depends_on:
      - flink-jobmanager
    networks:
      - chronon-net

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka
    ports:
      - "9092:9092"
      - "19092:19092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://:9093,PLAINTEXT_HOST://:19092"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:19092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"  # static for single-node KRaft
    networks:
      - chronon-net

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      DYNAMIC_CONFIG_ENABLED: 'true'
    depends_on:
      - kafka
    restart: unless-stopped
    networks:
      - chronon-net

  dynamodb-local:
    image: amazon/dynamodb-local:latest
    container_name: dynamodb-local
    ports:
      - "8000:8000"
    volumes:
      - ./dynamodb-data:/home/dynamodblocal/data
    command: ["-jar", "DynamoDBLocal.jar", "-sharedDb", "-dbPath", "/home/dynamodblocal/data"]
    restart: unless-stopped
    networks:
      - chronon-net
    user: "1000:1000"

  dynamodb-admin:
    image: aaronshaf/dynamodb-admin:latest
    container_name: dynamodb-admin
    ports:
      - "8001:8001"
    environment:
      - DYNAMO_ENDPOINT=http://dynamodb-local:8000
      - AWS_REGION=us-west-2
      - AWS_ACCESS_KEY_ID=local
      - AWS_SECRET_ACCESS_KEY=local
    depends_on:
      - dynamodb-local
    restart: unless-stopped
    networks:
      - chronon-net

  duckui:
    build:
      context: ./duckui
    environment:
      SPARK_WAREHOUSE_PATH: /srv/chronon/metastore/warehouse
    volumes:
      - ./duckui:/srv/chronon/duckui
      - ./metastore:/srv/chronon/metastore:ro
    working_dir: /srv/chronon/duckui
    ports:
      - "8501:8501"
    command: ["streamlit", "run", "app.py", "--server.address=0.0.0.0", "--server.port=8501"]
    depends_on:
      - chronon-spark
    networks:
      - chronon-net

networks:
  chronon-net:
